# The use of AI

AI tools like ChatGPT can be incredibly helpful when learning a new programming language, such as Python. They offer quick answers, code snippets, and explanations that can speed up your learning process. However, it’s crucial to remember that AI-generated code is only as good as the instructions it receives, and it cannot always guarantee accuracy or context-specific solutions.

To truly master Python, it’s essential to build a solid foundation of programming knowledge. Without understanding the core concepts and logic of the language, you might struggle to evaluate whether the code provided by AI tools is correct or suited to your needs. Only by having this base will you be able to discern good code from bad and make informed decisions during your programming journey.

Therefore, while AI can be a useful assistant, it cannot replace the deep learning and practice required to truly grasp the language and its applications. Keep this in mind as you continue developing your skills in Python.

### Note:
Typical plagiarism (i.e., copying from other sources without citation) is strictly prohibited at Goethe University, and all instances of academic dishonesty, including unauthorized AI use, will be dealt with according to the established regulations.

## Guidelines for Handling Suspected Cases of Unauthorized Use of AI Tools in Written Work

At Goethe University, a working group has been established to address the emerging need for regulations concerning the use of AI tools in higher education. This group is currently developing a guide aimed at educators, students, and the institution as a whole. Until this guide is available, the following document provides interim guidance for handling suspected cases of unauthorized use of AI tools in written assignments and assessments.

### The Challenge of Handling AI Misuse Suspicions

Given the novelty of this issue, no legal precedents currently exist. Therefore, existing principles for handling cases of suspected academic misconduct should be applied.

## 1. Handling Suspected Cases of Unauthorized AI Use

### a) Identifying Academic Misconduct

The general approach to academic misconduct is outlined in Section 29 of the Framework Regulations, and specific program regulations also apply. To ensure fairness, students must submit their own work using only permitted resources as outlined in the exam regulations or by the instructor. Misconduct occurs when a student falsely represents their work as independent while using unauthorized or undisclosed assistance.

In the context of AI tools, misconduct may occur if a student incorporates AI-generated content without marking it as a resource. If AI tools are used to generate a substantial portion of the work, it ceases to be the student's own. While this is not traditional plagiarism (since the text is generated by software rather than copied from a person), it still misrepresents the student’s independent contribution.

Typically, the requirement to disclose the use of AI tools arises from the declaration of independent work that students must submit, confirming they have listed all resources used.

### b) Proving Misconduct or Attempted Misconduct

It is the responsibility of the examination board to address suspected cases of academic misconduct. If there is suspicion of unauthorized AI use, instructors must report their concerns to the examination board, providing supporting evidence.

However, proving the use of AI tools in academic misconduct cases remains challenging. Current AI detection tools, such as AI Text Classifier and ChatGPT Zero, are not reliable enough to serve as definitive proof. The law allows for an “apparent evidence” rule in cases of suspected misconduct, meaning that evidence is considered sufficient if it strongly suggests typical behavior that points to misconduct.

For example, if fabricated sources are cited—something AI tools are known to generate—this may constitute apparent evidence. Additionally, a pattern of inconsistencies in writing style, combined with AI detection results, could further support suspicions of AI tool use.

If apparent evidence is present, the student can challenge the suspicion by offering a plausible alternative explanation for the irregularities. They are not required to prove their innocence, but they must demonstrate that another explanation for the issues is feasible.

If sufficient evidence of misconduct cannot be provided, the exam should be graded as usual.

## 2. Consequences for Misconduct

The general rules for academic misconduct apply. This may include failing the assignment or further disciplinary actions, depending on the severity of the case.

## 3. Conclusion

Steps for handling suspected cases of AI misuse:

1. Instructors should report suspicions to the examination board.
2. The examination board will assess whether apparent evidence of misconduct exists based on the case details.
3. If apparent evidence is present, the student may be invited for a discussion to address the concerns.
4. If the student successfully refutes the suspicion, the work will be graded as usual.
5. If apparent evidence is not refuted, the work will be treated as academic misconduct.

For further questions, the Study and Examination Law team is available at:

**studienrecht@uni-frankfurt.de**


